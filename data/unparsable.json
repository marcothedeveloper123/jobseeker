[
    " [{\"skill\": \"General Purpose Python Programming, Database Design and SQL, Version Control and CI/CD\", \"reference\": \"\"You have demonstrated competencies in the subject areas: General Purpose Python Programming, Database Design and SQL, and Version Control and CI/CD.\"\"},\n{\"skill\": \"Cloud Infrastructure and AWS, Web API Server and Client Development, Distributed Computing\", \"reference\": \"\"Candidates should be proficient in Cloud Infrastructure with AWS, Web APIs, and Distributed Computing.\"\"},\n{\"skill\": \"Required Soft Skills, Preferred Technical Competencies\", \"reference\": \"\"You have demonstrated soft skills and professional capacity in various technical competencies.\"}]",
    " [{\"skill\": \"Python, Machine Learning, SQL\", \"reference\": \"Look for strong job history, Python, Machine Learning, SQL, 10/10 comms, etc.\"},\n {\"skill\": \"Engineer Summary\", \"reference\": \"\"We're looking for an experienced Data Engineer to join our client's growing team of top notched IT professionals\"\"},\n {\"skill\": \"Data Engineering, Multiple Groups Collaboration\", \"reference\": \"You will work closely across multiple groups including Editorial and Audio, Marketing, Advertising, etc.\"},\n {\"skill\": \"Solidify & Expand Pipelines, Maintain Data Warehouse\", \"reference\": \"As the company grows, they're looking for a Data Engineer who will help solidify and expand our pipelines and maintain their data warehouse\"},\n {\"skill\": \"Complex Analyses, Product Performances, User Behaviour\", \"reference\": \"Their business model is based on performing complex and very detailed analyses of how our products perform with their subscribers.\"},\n {\"skill\": \"Data Pipelines, Insights, Drive Business Decisions\", \"reference\": \"Create and maintain data pipelines to provide insights and drive business decisions\"},\n {\"skill\": \"Data Warehousing Strategies\", \"reference\": \"Establish data warehousing strategy (ex. Kimball, Data Vault, etc.)\"},\n {\"skill\": \"Maintain Data Infrastructure on AWS\", \"reference\": \"Maintain data infrastructure on our AWS accounts\"},\n {\"skill\": \"Collaborate with Analytics & Business Teams\", \"reference\": \"Work alongside analysts, product, marketing, and other teams to define new data collection components and measurement schemes that support each new product and feature.\"},\n {\"skill\": \"Create Data Models, BI Reporting Tools\", \"reference\": \"Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders\"},\n {\"skill\": \"Secure Architectures, Documentation & Procedures\", \"reference\": \"Write unit/integration tests, contributes to engineering wiki, and documents work\"},\n {\"skill\": \"Experience in Measuring Product Performance & User Behavior\", \"reference\": \"7+ years of industry experience measuring product performance and user behavior\"},\n {\"skill\": \"Knowledge of Data Management Technologies\", \"reference\": \"Experience working with a variety of data management technologies, including RedShift, Kinesis/Kafka, Glue, Spark, Postgres, Airflow, dbt, and others.\"},\n {\"skill\": \"BI Reporting Tools Experience\", \"reference\": \"Experience implementing BI reporting tools such as Looker\"},\n {\"skill\": \"Communication Skills for Data Needs\", \"reference\": \"Interfacing with engineers, product managers and analysts to understand data needs\"},\n {\"skill\": \"Measurement Techniques for Success\", \"reference\": \"Understanding of the typical metrics a subscription and advertising-supported business needs to measure success\"},\n {\"skill\": \"Segmentation or Anomaly Identification\", \"reference\": \"Experience with Client techniques as applied to behavioral segmentation or anomaly identification is a definite plus\"},\n {\"skill\": \"Familiarity with Developer Tools\", \"reference\": \"Familiarity using developer tools that increase productivity and facilitate the development of resilient code (eg. Docker, CircleCI, Serverless) is a plus\"}]",
    " [\n  { \"skill\": \"Talent Pool Management\", \"reference\": \"We are inviting professionals in high-growth industries to join our expanding talent pool.\" },\n  { \"skill\": \"F4S Work Style Assessment\", \"reference\": \"Once you express your interest, you will be asked to complete the F4S work style assessment.\" },\n  { \"skill\": \"Personal and Team Motivation Forecasting\", \"reference\": \"Backed by 20+ years of research, F4S\u2019s revolutionary predictive analytics have achieved over 90% reliability in forecasting personal and team motivations, behaviors, and performance.\" },\n]",
    " [\n  { \"skill\": [\"Bachelors degree or Masters degree in Computer Science\", \"Motivated, self-learner and technically inquisitive\", \"Experience in programming language Java\"], \"reference\": \"For Java /Software Programmers\" },\n  { \"skill\": [\"Bachelors degree or Masters degree in Computer Science\", \"Motivated, self-learner and technically inquisitive\", \"Experience in programming language Java\"], \"reference\": \"For data Science/Machine learning Required Skills\" },\n  { \"skill\": [\"Bachelors degree or Masters degree in Computer Science\", \"Motivated, self-learner and technically inquisitive\", \"Experience in programming language Java\"], \"reference\": \"Required Skills For Java /Full Stack/Software Programmer\" },\n  { \"skill\": [\"Bachelors degree or Masters degree in Computer Science\", \"Motivated, self-learner and technically inquisitive\", \"Experience in programming language Java\", \"Knowledge of Core Java , javascript , C++ or software programming Spring boot, Microservices, Docker, Jenkins and REST API's experience\"], \"reference\": \"Required Skills For Full Stack/Software Programmer\" },\n  { \"skill\": [\"Bachelors degree or Masters degree in Computer Science\", \"Motivated, self-learner and technically inquisitive\", \"Experience in programming language Java\", \"Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools\"], \"reference\": \"Required Skills For data Science/Machine learning Positions\" },\n  { \"skill\": [\"NLP, Text mining, Tableau, PowerBI, Tensorflow\"], \"reference\": \"Preferred skills: NLP, Text mining, Tableau, PowerBI, Tensorflow\"},\n]",
    " [\n  { \"skill\": [\"Hive\", \"KAFKA\", \"Python\", \"SPARK\", \"UNIX\", \"Hadoop platform\"], \"reference\": \"Required (Individual Role) Extensive experience in engineering and designing data management solutions using Hadoop platform tools and technologies\" },\n  { \"skill\": [\"Data ingestion pipeline process\", \"exception handling\", \"metadata management\", \"automated data integration applications\", \"data warehouses\", \"operational data stores\", \"data marts\", \"data lakes\"], \"reference\": \"\"Hands-on experience creating automated data integration applications using data models, data mappings and business rules specifications to load data warehouses, operational data stores, data marts, and data lakes while programmatically handling exceptions including late arriving, missing, or erroneous data.\"\" },\n  { \"skill\": [\"UNIX shell scripting\", \"Data Quality checks\", \"Data Movement controls\", \"enabling access to data by way of databases or dashboards\"], \"reference\": \"\"Experience in UNIX shell scripting Demonstrated experience developing/expanding automated technology controls (e.g., Data Quality checks, Data Movement controls) Demonstrated experience enabling access to data by way of databases or dashboards.\"\" },\n  { \"skill\": [\"Cleaning\", \"filtering\", \"transforming\", \"enriching data\"], \"reference\": \"\"Experience in cleaning, filtering, transforming data, and/or enriching data.\"\" }\n]",
    " [{ \"skill\": [\"Data Engineering\", \"Data Analytics\"], \"reference\": \"The Data Engineer is a member of our Data Engineering team who will focus on data analytics, data engineering and report development to meet business requirements.\"},\n { \"skill\": [\"Healthcare Measures\", \"Data Extraction\", \"Data Pipelines\"], \"reference\": \"A successful candidate has experience building healthcare measures, efficiently retrieving data from a data lake, build and troubleshooting data pipelines and developing automated data set processes.\"},\n { \"skill\": [\"Technology Strategies\", \"Healthcare Outcomes\"], \"reference\": \"In this role, you'll influence technology strategies, ensure that the technological solutions are aligned with the company's business needs and bring to life data and how it can impact positive healthcare outcomes.\"},\n { \"skill\": [\"Data Ingestion & Transformation Pipelines\", \"Big Data Technologies\"], \"reference\": \"Design & implement big data ingestion & transformation pipelines in order to publish data for consumption. Develop & champion best practices for large scale information extraction from structured/semi-structured data sources.\"},\n { \"skill\": [\"Data Extraction & Processing Pipelines\", \"Improve Data Quality\"], \"reference\": \"Understand data sources in-depth; design & implement data extraction & processing pipelines that work around imperfections of data to improve data quality & coverage.\"},\n { \"skill\": [\"Automated Test Coverage\", \"Scalable Code Development\"], \"reference\": \"Deliver high-quality, scalable code with automated test coverage. Drive data quality across the product vertical and related business areas.\"},\n { \"skill\": [\"SLAs for Data Sets & Processes\", \"High Impact Dashboards\"], \"reference\": \"Support the delivery of high impact dashboards and data visualizations. Define and manage SLAs for all data sets and processes running in production.\"},\n { \"skill\": [\"Bachelor's Degree or Equivalent Experience\", \"4 Years of Related Experience\"], \"reference\": \"We're Looking for People Who Have: A bachelor's degree in a technical or business discipline, or equivalent experience. 4 years of related data engineering, software engineering and/or business intelligence experience.\"},\n { \"skill\": [\"SAS, SQL Languages\", \"3 Years of Experience with Big Data Technologies\"], \"reference\": \"Minimum of 4 years of experience in creating reports using SAS, SQL languages. 3 years of hands-on experience with big data technologies & event driven architecture.\"},\n { \"skill\": [\"NCQA/HEDIS Quality Measures\", \"Cloud-Based Data Platforms (AWS Stack & Snowflake)\"], \"reference\": \"Experience working in building NCQA/HEDIS quality measures to measure quality performance rates is preferred. Ability to develop highly scalable cloud-based data platforms.\"},\n { \"skill\": [\"Data Modeling & Architecture\", \"Object-Oriented Languages\"], \"reference\": \"Progressive experience with SQL and related data base technologies. Progressive experience with a variety of data management tools and technologies, and related tools, data visualization and data extraction and transformation tools. Must have strong problem-solving, analytical and in-depth research skills.\"},\n { \"skill\": [\"Problem Solving\", \"Communication Skills\"], \"reference\": \"Possess the ability to communicate effectively with internal and external partners, both orally and written.\"},\n { \"skill\": [\"DBT Experience\", \"PowerBI or Tableau Preferred\"], \"reference\": \"Experience using DBT is preferred. Experience with PowerBI or Tableau preferred.\"},\n { \"skill\": [\"Compensation Based on Experience & Relevant Certifications\"], \"reference\": \"Full compensation packages are based on candidate experience and relevant certifications.$135,000\u2014$140,000 USD\"},\n { \"skill\": [\"Diversity & Inclusion\", \"Equal Opportunity Employer\"], \"reference\": \"XO Health is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law.\"},\n { \"skill\": [\"Drug-Free Workplace\"], \"reference\": \"XO Health promotes a drug-free workplace.\"}",
    " [\n  { \"skill\": [\"GenRocket\", \"scripting\", \"PostGres/DB ability\", \"API work\"], \"reference\": \"Must required: GenRocket, scripting, PostGres/DB ability, API work\"},\n  { \"skill\": [\"Best practice\", \"Data Hub\", \"Synthetic data\", \"Solution creation\", \"Data models\", \"Table structures\", \"Dependencies\", \"Team guidance\"], \"reference\": \"Determine best practice(s) around synthetic, masked data in DCE/Platform; Analyze and understand how data flows in data hub; Determine the way to manage and create synthetic data in Data Hub; deliver solution; Understanding data models, table structures and dependencies; Guide teams in generating new synthetic data\" },\n  { \"skill\": [\"Agile Mindset\", \"Azure Cloud\", \"ADO experience\", \"Python/PowerShell scripting\"], \"reference\": \"Agile Mindset, familiarity with Azure Cloud ADO experience, python or powershell scripting experience\"},\n]",
    " [\n    { \"skill\": \"Lead Data Engineer\", \"reference\": \"About the job\" },\n    { \"skill\": \"Dynamic and experienced Lead Data Engineer\", \"reference\": \"About the job\" },\n    { \"skill\": \"Collaborate with team of data scientists, engineers, and analysts\", \"reference\": \"Key Responsibilities\" },\n    { \"skill\": \"Write big data pipelines in Python and DBT transformations in SQL\", \"reference\": \"Key Responsibilities\" },\n    { \"skill\": \"Strong technical background, passion for data processing, ability to think creatively and strategically\", \"Minimum Qualifications\" },\n    { \"skill\": \"Write test and maintain code in Python and DBT data models on Snowflake\", \"Key Responsibilities\" },\n    { \"skill\": \"Work with cross-functional teams, gather requirements, develop software solutions\", \"Key Responsibilities\" },\n    { \"skill\": \"Design, construct, install, test, maintain highly scalable data management systems\", \"Key Responsibilities\" },\n    { \"skill\": \"Provide debugging and troubleshooting support for existing systems\", \"Key Responsibilities\" },\n    { \"skill\": \"Participate in code reviews to ensure software quality\", \"Key Responsibilities\" },\n    { \"skill\": \"Assist in database design and Snowflake data warehouse development\", \"Key Responsibilities\" },\n    { \"skill\": \"Leverage AWS, cloud technologies for efficient deployment and scalability\", \"Key Responsibilities\" },\n    { \"skill\": \"Use Python to process data, manage ETL pipelines, create automated workflows\", \"Key Responsibilities\" },\n    { \"skill\": \"5+ years of experience in designing, implementing and maintaining relational/data warehousing environments\", \"Minimum Qualifications\" },\n    { \"skill\": \"Strong proficiency in programming languages commonly used in data engineering (Python, SQL)\", \"Minimum Qualifications\" },\n    { \"skill\": \"Experience working with data warehouses and relational databases\", \"Minimum Qualifications\" },\n    { \"skill\": \"Familiarity with AWS or cloud-based technologies\", \"Minimum Qualifications\" },\n    { \"skill\": \"Big Data technologies experience (Hadoop, Spark)\", \"Minimum Qualifications\" },\n    { \"skill\": \"Problem-solving skills, attention to detail\", \"Preferred Qualifications\" },\n    { \"skill\": \"Ability to work independently and as part of a team\", \"Key Requirements\" },\n    { \"skill\": \"Excellent verbal and written communication skills\", \"Minimum Qualifications\" }\n]",
    " [\n  { \"skill\": [\"Design and develop an end-to-end Camunda application\", \"Have experience with business rules and decision tables\", \"Have experience in Java technologies\"], \"reference\": \"Must have skills: Design and develop an end-to-end Camunda application. Have experience with business rules and decision tables. Have experience in Java technologies.\" },\n  { \"skill\": [\"Ability to understand Business Problem and provide BPM centric solution\", \"Conversant with latest versions and features of Camunda (ver 8)\", \"Maintain application with reusable components for rapid application building\"], \"reference\": \"Additional Skills Ability to understand Business Problem and provide BPM centric solution through digitized process, automations, User Interventions, and well-defined User Experience. Conversant with latest versions and features of Camunda (ver 8) and be able to maintain application with reusable components for rapid application building in future\" },\n  { \"skill\": [\"Camunda BPM Development\", \"Java/J2EE\"], \"reference\": \"Roles and Responsibilities Integrate and maintain Camunda BPM solutions through the systems development lifecycle. Hands-on development, coding, debugging of Camunda BPM applications.\" },\n  { \"skill\": [\"Design and develop an end-to-end Camunda 8 application\", \"Have experience with business rules and decision tables\", \"Have experience in Java technologies\"], \"reference\": \"\"Required Skills: Design and develop an end-to-end Camunda 8 application. Have experience with business rules and decision tables. Have experience in Java technologies.\"\" },\n  { \"skill\": [\"Hands on experience with BPMN, J2EE technologies, REST, open-source products, database, ability to review variety of code\", \"Have experience integrating with an external content management system\", \"Building dashboards for Camunda Operate\"], \"reference\": \"\"Preferred Skills Hands on experience with BPMN, J2EE technologies, REST, open-source products, database, and ability to review variety of code. Have experience integrating with an external content management system. Have experience building dashboards for Camunda Operate.\"\" },\n  { \"skill\": [\"Team player\", \"Good communicator\", \"Result oriented\", \"Working with virtual/distributed teams\"], \"reference\": \"\"Behavioral Skills: Team player and a good communicator. Result oriented with ability to work with virtual/distributed teams.\"\" }\n]",
    " [\n    { \"skill\": [\"GenRocket\", \"scripting\", \"PostGres/DB ability\", \"API work\"], \"reference\": \"Must required: GenRocket, scripting, PostGres/DB ability, API work\"},\n    { \"skill\": [\"Best practice for synthetic data\", \"Data flow understanding\", \"Synthetic Data Management\", \"Solution creation\", \"Mock massive accounts\", \"Data model knowledge\", \"New synthetic data generation\", \"Maintain synthetic data\", \"PoC creation with Product team\"], \"reference\": \"\"Determine best practice(s) around synthetic, masked data in DCE/Platform; Analyze and understand how data flows in Data Hub; Determine best way to manage and create synthetic data in Data Hub; deliver solution; Figure out a solution to mock massive accounts coming through APIs; Understanding data models, table structures and dependencies. Guide teams in generating new synthetic data, creating more, and maintaining over time. Create PoC for syntheitc data use cases working with Product team\"\"},\n    { \"skill\": [\"Agile Mindset\", \"Azure Cloud familiarity\", \"ADO experience\", \"Python or PowerShell scripting\"], \"reference\": \"\"Agile Mindset, familiarity with Azure Cloud ADO experience, python or powershell scripting experience\"\"}\n]",
    " [{ \"skill\": \"Senior Data Analytics Engineer\", \"reference\": \"We are seeking a highly motivated Senior Data Analytics Engineer to join our Analytics Data Engineering team inside of Data Science.\"},\n{ \"skill\": \"Data Engineering Expertise\", \"reference\": \"At least five years of industry experience in data engineering or related roles such as Software EngineeringRemote employment experienceExperience with several of EMR, Spark, Kinesis, Athena, and AirflowRespected by peers for technical prowess in Scala. Python is a plus\"},\n{ \"skill\": \"Data-driven Problem Solving\", \"reference\": \"Build pipelines that source data from operational systems and then process and organize it to optimize for R&D efforts across Arity Apply appropriate methodologies for the problem using a variety of tool sets and writing code in Scala or Python.\"},\n{ \"skill\": \"Data Science & Machine Learning\", \"reference\": \"Experience moving trained machine learning models\"},\n{ \"skill\": \"Team Collaboration\", \"reference\": \"Work with a team of data engineers dedicated to creating the best telematics data and insights platform in the market. You will help us build the next generation of deep mobility insights by extracting relevant behavioral and geospatial patterns from users' trip data.\"},\n{ \"skill\": \"Data Innovation\", \"reference\": \"Drive continuous improvement of data science and data engineering practices to create world-class capabilities Influence analytics strategy and roadmap with your combination of data engineering expertise and domain experience Build the Arity technical brand by engaging in conferences, meetups, blogs, and other external public engagements\"},\n{ \"skill\": \"Leadership\", \"reference\": \"Inspire, mentor, and enable team to be bold and deliver high quality work Comfortable in a fast-paced environment with high ambiguity; inspires others to embrace these conditions\"}",
    " [\n  { \"skill\": [\"data and analytics solutions\", \"modern data platform\", \"advanced experience\"], \"reference\": \"JOB DESCRIPTION: Significant experience implementing advanced data and analytics solutions on a modern data platform (e.g., Dremio, Databricks, Snowflake)\" },\n  { \"skill\": [\"Kubernetes\", \"networking policies\", \"configurations\"], \"reference\": \"Experience working with Kubernetes and dealing with networking policies and configurations.\" },\n  { \"skill\": [\"enterprise data visualization tools\", \"experience configuring\"], \"reference\": \"Experience working with and configuring enterprise data visualization tools (e.g., Qlik, Tableau, Power BI)\" },\n  { \"skill\": [\"build rapport\", \"close working relationship\"], \"reference\": \"Ability to effortlessly build rapport and maintain close working relationship with technical colleagues.\" },\n  { \"skill\": [\"5+ years' experience SQL\", \"Scala, Python, Java\"], \"reference\": \"\"You will be familiar with 5+ years' experience with SQL, 5+ years' experience writing Scala, Python, or Java\"\" },\n  { \"skill\": [\"Git and DevOps tooling\", \"containerization ecosystem\"], \"reference\": \"You will be familiar with Git and DevOps tooling. You will be familiar with containerization and the surrounding ecosystem, including secrets management.\" },\n  { \"skill\": [\"Agile methodologies\"], \"reference\": \"Experience working with Agile methodologies.\" },\n  { \"skill\": [\"Kafka\", \"experience configuring\", \"work with data masking anonymization techniques\"], \"reference\": \"Additional Qualifications Experience configuring and working with Kafka.Experience working with data masking and anonymization techniques.\" },\n  { \"skill\": [\"modern and legacy data sources\", \"structures\", \"experience working\"], \"reference\": \"Experience working with DBT or other modern data development tools.Experience working across both modern and legacy data sources and structures.\" },\n  { \"skill\": [\"Front/Backend development\", \"Workflow Decision automation\"], \"reference\": \"Good understanding of Front/Backend developmentExposure to Workflow and Decision automation (e.g., Camunda, Airflow)\" }\n]",
    " [{ \"skill\": [\"ELT/ETL designer/developer\", \"SQL & Python expert\", \"Performance tuning with SQL\"], \"reference\": \"Strong ELT/ ETL designer/developer Strong SQL & Python Expert level Performance tuning with SQL\" },\n{ \"skill\": [\"Cloud environment development\", \"Data modeling experience\"], \"reference\": \"\"Preference for candidates experienced with: Google Cloud Platform (GCP) and associated services; e.g., Big Query, GCS, Cloud Composer, Dataproc, Dataflow, Dataprep, Cloud Pub/Sub, Metadata DB, Data Studio, Datalab, other tools Apache Airflow (scheduler), Bitbucket Real-time data replication/streaming tools\"\" },\n{ \"skill\": [\"Apache Airflow\", \"Bitbucket\"], \"reference\": \"\"Apache Airflow (scheduler), Bitbucket\"\" }]",
    " [\n  { \"skill\": [\"AWS/Snowflake/DBT experiences\", \"10+ years of prior experience Lead Data Engineer\"], \"reference\": \"Job Title: Lead Data Engineer\" },\n  { \"skill\": [\"SQL, Python, automation\", \"Experience with Tableau or visualization tool\"], \"reference\": \"Must be proficient in SQL, Python. Automate repetitive personal tasks through Python and SQL\" },\n  { \"skill\": [\"Relational databases like SQL Server, MySQL, Vertica, NoSQL databases experience\", \"Kafka consumers/producers, Apache Spark Streaming, Hive\"], \"reference\": \"Experience with relational databases like SQL Server, MySQL and Vertica. NoSQL databases experience is a plus. Experience with Kafka consumers and producers. Experience Apache Spark Streaming and Hive is plus.\" },\n  { \"skill\": [\"Linux servers, Docker\", \"User-defined workflows (e.g., Airflow)\"], \"reference\": \"Experience with Linux servers and Docker is required. Problem solver that is action-oriented with the ability to look at problems in new ways. Working knowledge of data management software like Airflow, or other ETL tools a plus.\" },\n  { \"skill\": [\"Strong analytical/problem-solving\", \"Support multiple on-going projects\"], \"reference\": \"Strong analytical and problem-solving ability to design an effective solution. Ability to support multiple on-going projects in a fast-paced environment.\" },\n  { \"skill\": [\"Communication, organization, negotiation, flexibility\", \"Superior business judgement\"], \"reference\": \"Strong communicational skills, organizational skills, negotiation skills, and flexibility to address competing demands. Superior business judgement ability to flex between big picture thinking\" },\n]",
    " [{\"skill\": [\"AEP\", \"Adobe Experience Platform\", \"Customer Data Platform\"], \"reference\": \"Mandatory Skill: AEP- Adobe Experience Platform\"},\n {\"skill\": [\"12+ Years Minimum\", \"Experience\", \"Project Duration\"], \"reference\": \"\"Role: Customer Data Platform EngineerLocation: California RemoteProject duration 3 months to long termExperience: 12+ Years Minimum\"\"},\n {\"skill\": [\"Adobe Experience Platform\", \"AEP- Adobe Experience Platform\", \"Customer Data Platform\"], \"reference\": \"We are looking for a CDP Engineer/Developer to join our team. Understand Adobe Experience Platform\"},\n {\"skill\": [\"Plan\", \"Design\", \"Build XDM schemas\", \"Adobe Experience Platform\"], \"reference\": \"Plan, design, and build XDM schemas in AEP to host imported data\"},\n {\"skill\": [\"Data Collection Strategy\", \"Real-Time CDP\", \"Journey Orchestration\", \"Personalization\", \"Customer Journey Analytics\", \"External Reporting Dashboard Solutions\"], \"reference\": \"\"Focus on Data collection Strategy, Real-Time CDP, Journey Orchestration, Personalization, Customer Journey Analytics and external reporting dashboard solutions\"\"},\n {\"skill\": [\"Modern Cloud Technologies\", \"Design Principles\", \"Integration Points\", \"Automation Methods\"], \"reference\": \"Design and advocate solutions using modern cloud technologies, design principles, integration points, and automation methods.\"},\n {\"skill\": [\"Quality Software\", \"Data Structures\", \"Implementation Enhancement Support\", \"Marketing Projects\"], \"reference\": \"\"The AEP Engineer creates quality software and data structures that meet the functional and non-functional project requirements in the implementation, enhancement, and support of marketing projects.\"\"},\n {\"skill\": [\"Application Code\", \"On-Time Budget Compliance\", \"Company Standards & Practices\"], \"reference\": \"\"This includes producing application code on-time, on-budget, and in compliance with company implementation standards & practices as well as general industry & platform\"\"},\n {\"skill\": [\"Large-Scale Data Systems\", \"Data Processing\", \"Data Transformation Projects\"], \"reference\": \"Lead, design, develop, and deliver large-scale data systems, data processing, and data transformation projects.\"}]",
    " [{\"skill\": \"Data Engineering Expertise\", \"reference\": \"You are responsible for building the infrastructure to support the storing and movement of data, so that it can be prepared by analytics engineers to eventually be interpreted by analysts.\"},\n{\"skill\": \"Cross-Team Collaboration\", \"reference\": \"Collaborate with peers and other functional departments to develop and implement data engineering strategies and approaches that support engagement goals and understanding client needs.\"},\n{\"skill\": \"Project Delivery\", \"reference\": \"Ensure that large and/or more complex data engineering projects are delivered on time, within scope, and within budget.\"},\n{\"skill\": \"Tools & Technologies\", \"reference\": \"\"See the latest Data Engineering framework. Data Movement You can reduce latency of end-to-end pipelines through data orchestration in addition to incrementalization or streaming. You have strong knowledge of common data integration patterns (CDC, ELT, etc.).Data Warehousing You have a high proficiency in warehousing, including working knowledge of common ingestion SaaS platforms (e.g., Fivetran) and / or frameworks (e.g., Meltano, Airbyte), an ability to configure warehouse ingestion tools (e.g., Snowpipe) and can provision, maintain and optimize at least one cloud data warehouse (e.g., Snowflake).Programming You are considered a highly proficient programmer, approaching your code holistically, achieving a high standard routinely. You can optimize performance for large workloads and are able to troubleshoot complex queries / functions. Proficiency in Python required.\"},\n{\"skill\": \"Domain Expertise\", \"reference\": \"You have a strong foundation of knowledge in domains in which you're working. You are able to relate how the business works with the goals of the immediate team.\"},\n{\"skill\": \"Technical Management\", \"reference\": \"Is able to display a clear technical confidence and understanding. For the most part, can use organizational- and team-specific tools independently.\"},\n{\"skill\": \"Bonus points for Data Modeling & Transformation\", \"reference\": \"You have high proficiency with data transformation tools such as dbt and expert proficiency in data modeling approaches and philosophies (Kimball, OBT).\"},\n{\"skill\": \"Essential Skills (Intangible Skills)\", \"reference\": \"\"Curiosity & Versatility You help your immediate peers to make decisions based on what projects need, not what they feel most comfortable doing. You have taken the initiative to seek out new ways to apply existing skills and knowledge. Collaboration & Partnership You can facilitate collaborative group activities and/or workshops with colleagues or external stakeholders.\"},\n{\"skill\": \"Effective Communication\", \"reference\": \"You reliably foster a culture of clear, concise, effective, audience-oriented communication for your team, other departments, and external stakeholders, ensuring those around you are actively listening as well as are understood.\"},\n{\"skill\": \"Developing Others\", \"reference\": \"You understand your team's domain, share knowledge frequently with your teammates and contribute to the team's documentation. You proactively watch for opportunities to share knowledge and encourage others to do the same.\"},\n{\"skill\": \"Culture & Togetherness\", \"reference\": \"\"You've openly stated your expectations of how your team works and acts, then demonstrated those expectations yourself. You help to coordinate and activate efforts towards a fairer, more diverse and safer workplace, using your position of influence to get things done.\"},\n{\"skill\": \"Qualifications (Must Haves)\", \"reference\": \"\"Proven experience as a Data Engineer or related role, with a focus on designing and developing data pipelines. Strong programming skills in Python and SQL. Experience with Scala and Rust is a plus but not required. Deep knowledge of data warehousing and ETL/ELT processes.\"\"},\n{\"skill\": \"Physical Requirements\", \"reference\": \"\"Frequent sitting at a desk performing work on a computer. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.\"},\n{\"skill\": \"Compensation\", \"reference\": \"\"We believe all team members should be rewarded competitively, using practices that are equitable and transparent. This philosophy ensures we're able to find, grow, and retain exceptional talent from a variety of backgrounds. The pay range for this role is up to $150,000 if based in the USA and up to $76,000 if based in El Salvador.\"},\n{\"skill\": \"Core Company Values\", \"reference\": \"\"Velir is an established mid-sized agency with a top-tier portfolio of clients, ranging from the world's largest non-profits to Fortune 500 brands. We pride ourselves on our people-first culture and a low-ego workplace that embraces experimentation, collaboration and continuous improvement.\"},\n{\"skill\": \"As an equal opportunity employer\", \"reference\": \"\"We are firmly committing to diversity, equity, and inclusion in our hiring efforts. We recognize that we need team members from all backgrounds and experiences to successfully shape a positive employee experience as well as deliver our product and service solutions. To that end, we actively seek candidates who can bring diverse experiences and backgrounds to our team.\"},\n{\"skill\": \"At this time, Velir does not sponsor candidates\", \"reference\": \"\"Unfortunately cannot accept those on OPT or CPT.\"}]",
    " [\n  { \"skill\": [\"Design and develop Azure framework\", \"Java programming and troubleshooting\", \"Azure Databricks Services\"], \"reference\": \"Role: Lead Data Engineer-Azure Databricks\" },\n  { \"skill\": [\"BigData, K8 / ETL experience\"], \"reference\": \"\"Should have BigData, K8 / ETL experience\"\" }\n]",
    " [{\"skill\": \"Data Science\", \"reference\": \"Our Data Science team is fueled by a passion to impact the future of mobility.\"}, {\"skill\": \"Machine Learning\", \"reference\": \"\"You'll help us build the next generation of deep mobility insights by extracting relevant behavioral and geospatial patterns from users' trip data.\"\"}, {\"skill\": \"Data Engineering\", \"reference\": \"Work with a team of data engineers dedicated to creating the best telematics data and insights platform in the market.\"}, {\"skill\": \"Analytics\", \"reference\": \"\"Build pipelines that source data from operational systems and then process and organize it to optimize for R&D efforts across Arity.\"\"}, {\"skill\": \"Scala\", \"reference\": \"Respected by peers for technical prowess in Scala. Python is a plus.\"}, {\"skill\": \"Data Transformation\", \"reference\": \"Experience moving trained machine learning models.\"}]",
    " [{ \"skill\": [\"Data Warehousing\", \"Engineer\", \"T-SQL\", \"Design\", \"Development\", \"Data Analysis\", \"Integration\"], \"reference\": \"Join a Thriving Team as a Data Warehousing Engineer\" },\n { \"skill\": [\"Ensure Data Quality\", \"Consistency\", \"Reliability\", \"Complex Datasets\", \"Insights\", \"Analysis\", \"Presentation\"], \"reference\": \"Responsibilities\" },\n { \"skill\": [\"Data Warehousing Concepts\", \"Infrastructure Alignment\", \"Data Migration\", \"Transformation\", \"Cleansing Projects\", \"Integrity\", \"Proficiency in T-SQL\"], \"reference\": \"Responsibilities, Qualifications\"}",
    " [\n    { \"skill\": [\"Data Engineer\", \"Proven experience\", \"SQL proficiency\"], \"reference\": \"Requirements: Proven experience as a Data Engineer or in a similar role, showcasing proficiency in data manipulation. Strong SQL proficiency\" },\n    { \"skill\": [\"Data Manipulation\", \"Relational Databases\", \"Programming Language\"], \"reference\": \"showcasing proficiency in data manipulation. Experience with relational databases, and competency in at least one programming language (e.g., Python, Java, Scala) for data processing and scripting\" },\n    { \"skill\": [\"Data Modeling\", \"Database Design\", \"Cloud Platforms\"], \"reference\": \"Knowledge of data modeling and database design principles. Understanding of cloud platforms such as AWS, Azure, or Google Cloud.\" },\n    { \"skill\": [\"Problem-Solving\", \"Communication\"], \"reference\": \"Excellent problem-solving skills and effective communication abilities\" },\n    { \"skill\": [\"Bachelor's Degree\", \"Computer Science\"], \"reference\": \"\" (Education: Bachelor's degree in Computer Science, Experience with data streaming technologies)\" },\n    { \"skill\": [\"Data Streaming Technologies\"], \"reference\": \"Experience with data streaming technologies\" },\n    { \"skill\": [\"Data Governance\", \"Security Best Practices\"], \"reference\": \"\" (Understanding of data governance and security best practices.\"),\n    { \"skill\": [\"AWS\", \"Databricks Technologies\"], \"reference\": \"Experience and certifications in AWS and Databricks technologies\" }\n]",
    " [\n  { \"skill\": [\"Data Engineer\", \"GCP\", \"Developing features\"], \"reference\": \"One of our largest national retail clients is looking for a Data Engineer to join their growing Data Ventures Organization.\" },\n  { \"skill\": [\"Scala/Spark\", \"SQL queries\", \"Big Query\"], \"reference\": \"80% of your day to day will be heads down in the data. The other 20% will be spent gathering requirements and stakeholder management.\" },\n  { \"skill\": [\"Hadoop Hive\", \"Airflow\", \"Python\"], \"reference\": \"\"Desired Skills: Hadoop Hive, GCP, Big query, Using Airflow as a scheduling tool, Python, Druid, Azure\"\" }\n]",
    " [{ \"skill\": [\"Data Engineering\", \"SQL queries\", \"ETL\", \".NET\", \"T-SQL\"], \"reference\": \"Requirements: Data Engineering, SQL queries, ETL, .NET, T-SQL\" },\n { \"skill\": [\"Oracle PL/SQL\"], \"reference\": \"Nice To Have Skills  Oracle PL/SQL\" },\n { \"skill\": [\"Data lake\\warehouse\", \"Product owners\", \"Data sources for visualization tools (Tableau)\", \"Data quality\", \"Project objectives on-time\", \"Quality\", \"Scope\"], \"reference\": \"What You Will Be Doing and What's In It for You\" }]",
    " [{ \"skill\": \"Data Engineering\", \"reference\": \"Position: Data Engineer\"},\n{ \"skill\": \"Media & Entertainment Industry Experience\", \"reference\": \"\"Industry: Media and Entertainment\"\"},\n{ \"skill\": \"New York City Location or Remote Work\", \"reference\": \"Location: New York City OR REMOTE\"}",
    " [\n  { \"skill\": \"Data Bricks, Kafka, Python, Spark, AWS, Docker/Kubernetes\", \"reference\": \"Experience with the following tools: Data bricks Kafka Python Spark AWS Docker/Kubernetes\" },\n  { \"skill\": \"7+ years experience, Analytics experience, Demonstrated record of learning\", \"reference\": \"\"Required Skills & Experience\"\" },\n  { \"skill\": \"Hands On (60%), Management (20%), Team Collaboration (20%)\", \"reference\": \"Daily Responsibilities: 60% Hands On 20% Management Duties 20% Team Collaboration\" }\n]",
    " [\n  { \"skill\": [\"Design and develop services\", \"Data modeling\"], \"reference\": \"About the Role\" },\n  { \"skill\": [\"Experience building data model driven declarative systems\", \"Expertise with service-based architectures\"], \"reference\": \"\"Experience building data model driven declarative systems Expertise with service-based architectures and distributed databases Experience with developing cloud-based or similar highly concurrent, distributed systems\"\" },\n  { \"skill\": [\"Familiarity with both relational databases and schema-less NoSQL\", \"Proficient in transforming data\"], \"reference\": \"Experience with relational databases and schema-less \u201cNoSQL\u201d or key-value stores Proficient in transforming structured and unstructured data\" },\n  { \"skill\": [\"Production quality code writing\", \"Testing\"], \"reference\": \"Experience writing production quality code in one of Python, Go, or C++ Comfortable with testing as a first-class activity: unit testing, integration / end-to-end testing, and associated automations\" },\n  { \"skill\": [\"Comfortable working in distributed environment\", \"Time zones\"], \"reference\": \"Collaborate with other teams on cross functional design Understand and evolve the larger system architecture and its impact on development and design Work in a distributed environment across multiple time zones\" }\n]",
    " [{\"skill\": \"Deep understanding of software-hardware interactions\", \"reference\": \"Someone with a deep understanding of software-hardware interactions that obsesses about low-level Linux configurations and optimizations\"}, {\"skill\": \"Linux environments experience\", \"reference\": \"Experience with Linux environments\"}, {\"skill\": \"Infrastructure tools like Docker, Kubernetes, Ansible, Packer, Terraform\", \"reference\": \"Deep experience and fluency with Linux environments\"}]\n[{\"skill\": \"Low-level Linux configurations & optimizations\", \"reference\": \"Someone with a deep understanding of software-hardware interactions that obsesses about low-level Linux configurations and optimizations\"}, {\"skill\": \"Linux environments experience\", \"reference\": \"Experience with Linux environments\"}, {\"skill\": \"Docker, Kubernetes, Ansible, Packer, Terraform skills\", \"reference\": \"Deep experience and fluency with Linux environments\"}]\n[{\"skill\": \"5+ years infrastructure management experience\", \"reference\": \"5+ years of infrastructure management experience including bare metal server management and operating system image creation and deployments\"}, {\"skill\": \"Bare metal server management\", \"reference\": \"\"}, {\"skill\": \"OS image creation & deployments\", \"reference\": \"\"}]\n[{\"skill\": \"Data center design planning\", \"reference\": \"Collaborate with IT teams to design and plan data center infrastructure, including server racks, networking equipment, power distribution, cooling systems, and security measures\"}, {\"skill\": \"Implementation of hardware & software solutions\", \"reference\": \"Implement and deploy hardware and software solutions in the data center environment\"}]\n[{\"skill\": \"Compliance & protocols monitoring\", \"reference\": \"Monitor data center systems for performance, availability, and security, and proactively address issues as they arise\"}, {\"skill\": \"Problem troubleshooting\", \"reference\": \"Troubleshoot hardware, software, and network problems to minimize downtime and maintain optimal performance\"}]\n[{\"skill\": \"Resource monitoring & optimization\", \"reference\": \"Monitor data center resources, including power consumption, cooling efficiency, and server utilization, to ensure scalability and efficient resource allocation\"}, {\"skill\": \"Performance analysis\", \"reference\": \"Analyze performance metrics and recommend upgrades or optimizations to meet growing business needs\"}]\n[{\"skill\": \"Networking & connectivity\", \"reference\": \"Configure and maintain network switches, routers, and firewalls to ensure seamless data flow and secure communication within the data center. Collaborate with network engineers to design and implement network architecture that supports high availability and redundancy.\"}, {\"skill\": \"Networking configuration\", \"reference\": \"\"}]\n[{\"skill\": \"Security & compliance measures\", \"reference\": \"Implement and maintain security measures to protect data center assets from physical and cyber threats. Ensure compliance with industry standards and regulations such as ISO 27001, NIST, and HIPAA, depending on the industry\"}, {\"skill\": \"Data protection knowledge\", \"reference\": \"\"}]\n[{\"skill\": \"Documentation management\", \"reference\": \"Create and maintain documentation for data center layouts, configurations, and procedures. Keep accurate records of hardware and software inventory, licenses, and maintenance schedules.\"}, {\"skill\": \"Records keeping & updating\", \"reference\": \"\"}]\n[{\"skill\": \"Vendor collaboration\", \"reference\": \"Collaborate with vendors and suppliers to procure data center equipment, negotiate contracts, and ensure timely delivery of hardware and services. Evaluate and recommend new technologies and solutions that enhance data center efficiency and performance.\"}, {\"skill\": \"Supplier management\", \"reference\": \"\"}]\n[{\"skill\": \"SRE experience (5+ years)\", \"reference\": \"5+ years of professional SRE experience\"}, {\"skill\": \"Architecture design & optimization experience\", \"reference\": \"5+ years of experience contributing to architecture and design (architecture, design patterns, reliability and scaling) of new and current systems\"}, {\"skill\": \"Bachelor's in Computer Science or relevant work experience\", \"reference\": \"Bachelor's Degree in Computer Science or related field, or 8+ years relevant work experience\"}]\n[{\"skill\": \"Data center infrastructure design knowledge\", \"reference\": \"Collaborate with IT teams to design and plan data center infrastructure, including server racks, networking equipment, power distribution, cooling systems, and security measures\"}, {\"skill\": \"Infrastructure setup & deployment\", \"reference\": \"Implement and deploy hardware and software solutions in the data center environment\"}]\n[{\"skill\": \"Problem-solving skills\", \"reference\": \"Strong troubleshooting and problem-solving skills. Knowledge of security best practices and experience implementing security measures in a data center environment.\"}, {\"skill\": \"Security implementation & maintenance\", \"reference\": \"\"}]\n[{\"skill\": \"Communication & collaboration abilities\", \"reference\": \"Excellent communication and collaboration skills for working with cross-functional teams and vendors\"}, {\"skill\": \"Vendor management proficiency\", \"reference\": \"Collaborate with vendors and suppliers to procure data center equipment, negotiate contracts, and ensure timely delivery of hardware and services. Evaluate and recommend new technologies and solutions that enhance data center efficiency and performance.\"}, {\"skill\": \"Teamwork & vendor handling skills\", \"reference\": \"\"}]\n[{\"skill\": \"Relevant certifications (CompTIA Server+, Cisco CCNA, VMware VCP, or equivalent)\", \"reference\": \"Familiarity with security best practices and experience implementing security measures in a data center environment. Relevant certifications such as CompTIA Server+, Cisco CCNA, VMware VCP, or equivalent, are a plus.\"}]\n[{\"skill\": \"SRE experience (5+ years)\", \"reference\": \"5+ years of professional SRE experience\"}, {\"skill\": \"Architecture design & optimization experience\", \"reference\": \"5+ years of experience contributing to architecture and design (architecture, design patterns, reliability and scaling) of new and current systems\"}, {\"skill\": \"Bachelor's in Computer Science or relevant work experience\", \"reference\": \"Bachelor's Degree in Computer Science or related field, or 8+ years relevant work experience\"}]",
    " [{ \"skill\": [\"Data Architect\", \"Dynamic\"], \"reference\": \"About the job\"},\n{ \"skill\": [\"Strong Data Warehouse / Data Lake platforms\", \"SQL databases\", \"Big data skills\"], \"reference\": \"This role requires a very strong aptitude in Data Warehouse / Data Lake platforms, relational and no-SQL databases, and big data skills.\"},\n{ \"skill\": [\"Designing, building, optimizing\", \"Data monitoring\", \"Troubleshooting\", \"Query optimization\"], \"reference\": \"Architect, design, build, migrate, and stabilize Data Warehouse / Data Lake platform. Analyze raw, structured, and unstructured data to identify and optimize data sets and entities of interest.\"},\n{ \"skill\": [\"Data modeling\", \"NoSQL storage\", \"Python scripting\"], \"reference\": \"Very strong understanding of database and analytical technologies in the industry including MPP databases, Data Warehouse architecture and design, BI reporting, Dashboard development, and NoSQL storage.\"},\n{ \"skill\": [\"Expert knowledge\", \"ETL tools experience\", \"Cloud-based solutions knowledge\"], \"reference\": \"Demonstrated experience in building, migrating, and scaling ETL and Data Warehouse / Data Lake platforms. Deep experience with cloud-based Data Warehouse / Data Lake solutions like Snowflake, AWS Redshift, AWS Lake Formation, or similar.\"},\n{ \"skill\": [\"Relational databases\", \"Dimensional modeling concepts\"], \"reference\": \"Deep experience working with varied forms of data infrastructure inclusive of relational databases such as SQL, MySQL, and No-SQL such as MongoDB, Elasticsearch. Experience in data warehousing inclusive of dimensional modeling concepts.\"},\n{ \"skill\": [\"Scripting languages\", \"Open-time-off policy\"], \"reference\": \"An excellent benefit package, including medical, dental, vision and life insurance; 401(k) plan with company match; Open time-off policy\"},\n{ \"skill\": [\"Dynamic team\", \"Innovation opportunities\"], \"reference\": \"The opportunity to join a dynamic team that landed into the top list of Inc. 5000 in 2022 You can make an immediate impact as PlanHub moves to dominate the industry!\"},\n{ \"skill\": [\"Remote-friendly\", \"Excellent benefit package\"], \"reference\": \"PlanHub offers: An awesome culture where you will be empowered, make an impact, learn a ton! Remote friendly Open time-off policy An excellent benefit package, including medical, dental, vision and life insurance 401(k) plan with company match\"},\n{ \"skill\": [\"West Palm Beach office\", \"Remote position\"], \"reference\": \"This position will be a remote position within the United States. Occasional trips to our West Palm Beach, FL office, may be required. Applicants must be authorized to work for any employer within the United States. We are unable to sponsor or take over sponsorship of an employment Visa at this time.\"}"
]